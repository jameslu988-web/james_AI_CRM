"""
Googleæœç´¢å®¢æˆ·æŒ–æ˜ - ä½¿ç”¨Google Custom Search API
"""

import os
import re
import httpx
import logging
from typing import List, Dict, Optional
from datetime import datetime

logger = logging.getLogger(__name__)


class GoogleScraper:
    """Googleæœç´¢çˆ¬è™« - ä½¿ç”¨å®˜æ–¹Custom Search API"""
    
    def __init__(self):
        # Google Custom Search APIé…ç½®
        self.api_key = os.getenv('GOOGLE_API_KEY', 'AIzaSyCpy6Tjsmee1db1G8WoRpougu8EihfpzZA')
        self.search_engine_id = os.getenv('GOOGLE_CSE_ID', 'a2ee9bf9e675c4043')
        self.base_url = 'https://www.googleapis.com/customsearch/v1'
        self.proxy_url = None
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
    
    def set_proxy(self, proxy_url: str):
        """è®¾ç½®SOCKS5ä»£ç†"""
        self.proxy_url = proxy_url
        logger.info(f"âœ… ä»£ç†å·²è®¾ç½®: {proxy_url}")
    
    def search_google(self, keyword: str, num_results: int = 10) -> List[Dict]:
        """
        ä½¿ç”¨Google Custom Search APIæœç´¢ï¼ˆæ”¯æŒåˆ†é¡µï¼‰
        
        å‚æ•°:
            keyword: æœç´¢å…³é”®è¯
            num_results: æœŸæœ›ç»“æœæ•°é‡ï¼ˆä¼šåˆ†å¤šæ¬¡è¯·æ±‚ï¼‰
        
        è¿”å›:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        results = []
        
        try:
            # é…ç½®httpxå®¢æˆ·ç«¯ï¼ˆæ”¯æŒSOCKS5ä»£ç†ï¼‰
            if self.proxy_url:
                proxies = {
                    "http://": self.proxy_url,
                    "https://": self.proxy_url
                }
                client = httpx.Client(proxies=proxies, timeout=30.0)
            else:
                client = httpx.Client(timeout=30.0)
            
            # Google APIæ¯æ¬¡æœ€å¤šè¿”å›10æ¡ï¼Œéœ€è¦åˆ†é¡µ
            pages_needed = (num_results + 9) // 10  # å‘ä¸Šå–æ•´
            
            logger.info(f"ğŸ” æœç´¢å…³é”®è¯: {keyword} (éœ€è¦ {pages_needed} é¡µ)")
            
            for page in range(pages_needed):
                start_index = page * 10 + 1  # Googleçš„startä»1å¼€å§‹
                
                # æ„å»ºAPIè¯·æ±‚
                params = {
                    'key': self.api_key,
                    'cx': self.search_engine_id,
                    'q': keyword,
                    'num': 10,  # æ¯é¡µ10æ¡
                    'start': start_index
                }
                
                logger.info(f"ğŸ“„ è¯·æ±‚ç¬¬ {page+1}/{pages_needed} é¡µ (start={start_index})")
                response = client.get(self.base_url, params=params)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    if 'items' in data:
                        for item in data['items']:
                            results.append({
                                'title': item.get('title', ''),
                                'url': item.get('link', ''),
                                'snippet': item.get('snippet', ''),
                                'keyword': keyword
                            })
                        
                        logger.info(f"âœ… ç¬¬{page+1}é¡µæ‰¾åˆ° {len(data['items'])} æ¡ç»“æœ")
                    else:
                        logger.warning(f"âš ï¸ ç¬¬{page+1}é¡µæ²¡æœ‰ç»“æœ")
                        break  # æ²¡æœ‰æ›´å¤šç»“æœäº†
                else:
                    logger.error(f"âŒ ç¬¬{page+1}é¡µè¯·æ±‚å¤±è´¥: {response.status_code}")
                    break
                
                # å·²ç»è·å¾—è¶³å¤Ÿç»“æœ
                if len(results) >= num_results:
                    break
            
            client.close()
            logger.info(f"âœ… æœç´¢å®Œæˆï¼Œå…±æ‰¾åˆ° {len(results)} æ¡ç»“æœ")
            
        except Exception as e:
            logger.error(f"âŒ æœç´¢å¤±è´¥ '{keyword}': {str(e)}")
        
        return results[:num_results]  # ç¡®ä¿ä¸è¶…è¿‡è¯·æ±‚æ•°é‡
    
    def find_prospects(self, keywords: List[str], limit: int = 50) -> List[Dict]:
        """
        æ‰¹é‡æœç´¢å¤šä¸ªå…³é”®è¯
        
        å‚æ•°:
            keywords: å…³é”®è¯åˆ—è¡¨
            limit: æ€»ç»“æœæ•°é‡é™åˆ¶
        
        è¿”å›:
            æ‰€æœ‰æœç´¢ç»“æœï¼ˆå»é‡ï¼‰
        """
        all_results = []
        seen_urls = set()
        
        for keyword in keywords:
            if len(all_results) >= limit:
                break
            
            # æ¯ä¸ªå…³é”®è¯æœç´¢10æ¡
            results = self.search_google(keyword, num_results=10)
            
            # å»é‡å¹¶æ·»åŠ 
            for result in results:
                url = result.get('url', '')
                if url and url not in seen_urls:
                    seen_urls.add(url)
                    all_results.append(result)
                    
                    if len(all_results) >= limit:
                        break
        
        logger.info(f"ğŸ¯ æœç´¢å®Œæˆï¼Œå…±è·å¾— {len(all_results)} æ¡å”¯ä¸€ç»“æœ")
        return all_results[:limit]
