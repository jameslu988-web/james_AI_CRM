"""
AI é‚®ä»¶åˆ†æå™¨
ä½¿ç”¨ aihubmix.com API è¿›è¡Œé‚®ä»¶æ™ºèƒ½åˆ†æ
"""

import os
import json
import traceback
from typing import Dict, Optional, List
import httpx
from datetime import datetime


class EmailAIAnalyzer:
    """é‚®ä»¶ AI åˆ†æå™¨"""
    
    def __init__(self, api_key: str = None, base_url: str = None):
        """
        åˆå§‹åŒ– AI åˆ†æå™¨
        
        å‚æ•°:
            api_key: aihubmix.com API Key
            base_url: API åŸºç¡€ URL
        """
        self.api_key = api_key or os.getenv('AIHUBMIX_API_KEY', 'sk-5dn0RF7nn31mpHNjEfC5Ca1579F447418aE48e7b0d8b18F7')
        self.base_url = base_url or os.getenv('AIHUBMIX_BASE_URL', 'https://aihubmix.com/v1')
        self.timeout = 30.0
        
    async def analyze_email(
        self, 
        subject: str, 
        body: str,
        from_email: str = None,
        model: str = "gpt-4o-mini"
    ) -> Dict:
        """
        åˆ†æé‚®ä»¶å†…å®¹
        
        å‚æ•°:
            subject: é‚®ä»¶ä¸»é¢˜
            body: é‚®ä»¶æ­£æ–‡
            from_email: å‘ä»¶äººé‚®ç®±
            model: AI æ¨¡å‹åç§°
            
        è¿”å›:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            # æ„å»ºåˆ†ææç¤ºè¯
            prompt = self._build_analysis_prompt(subject, body, from_email)
            
            # è°ƒç”¨ AI API
            result = await self._call_api(prompt, model)
            
            # è§£æç»“æœ
            analysis = self._parse_analysis_result(result)
            
            return {
                "success": True,
                "analysis": analysis,
                "model": model,
                "analyzed_at": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            print(f"âŒ AI åˆ†æå¤±è´¥: {str(e)}")
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "analysis": self._get_default_analysis()
            }
    
    def _build_analysis_prompt(self, subject: str, body: str, from_email: str = None) -> str:
        """æ„å»ºåˆ†ææç¤ºè¯ï¼ˆä¸¥æ ¼æŒ‰ç…§ç³»ç»Ÿæ–¹æ¡ˆï¼‰"""
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤–è´¸é‚®ä»¶AIæ™ºèƒ½åˆ†æå¼•æ“ã€‚è¯·æ·±åº¦åˆ†æä»¥ä¸‹é‚®ä»¶ï¼Œä¸¥æ ¼æŒ‰ç…§å¤–è´¸ä¸šåŠ¡æµç¨‹è¿›è¡Œå¤šç»´åº¦è¯„ä¼°ã€‚

ã€é‚®ä»¶ä¿¡æ¯ã€‘
ä¸»é¢˜: {subject}
æ­£æ–‡: {body}
"""
        if from_email:
            prompt += f"å‘ä»¶äºº: {from_email}\n"
        
        prompt += """

è¯·è¿›è¡Œå…¨é¢çš„æ™ºèƒ½åˆ†æå¹¶è¿”å›ä»¥ä¸‹JSONæ ¼å¼ç»“æœï¼ˆåªè¿”å›JSONï¼Œä¸è¦å…¶ä»–è§£é‡Šï¼‰ï¼š

{
  "ä¸šåŠ¡é˜¶æ®µåˆ†ç±»": {
    "primary_stage": "æ–°å®¢è¯¢ç›˜|æŠ¥ä»·è·Ÿè¿›|æ ·å“é˜¶æ®µ|è°ˆåˆ¤è®®ä»·|è®¢å•ç¡®è®¤|ç”Ÿäº§è·Ÿè¸ª|å”®åæœåŠ¡|è€å®¢ç»´æŠ¤|åƒåœ¾è¥é”€",
    "secondary_category": "äº§å“ä¿¡æ¯|ä»·æ ¼è¯¢é—®|å®šåˆ¶éœ€æ±‚|æ ·å“ç”³è¯·|è®¤è¯èµ„è´¨|ç‰©æµè¿è¾“|ä»˜æ¬¾æ–¹å¼|èµ·è®¢é‡|å”®åé—®é¢˜"
  },
  
  "å®¢æˆ·æ„å›¾è¯†åˆ«": {
    "purchase_intent": "high|medium|low",
    "purchase_intent_score": 0-100,
    "budget_level": "é«˜ç«¯|ä¸­ç«¯|ä½ç«¯",
    "urgency": "æ€¥å•|å¸¸è§„|é•¿æœŸè®¡åˆ’",
    "decision_authority": "å†³ç­–è€…|é‡‡è´­ç»ç†|é‡‡è´­å‘˜|è¯¢ä»·å‘˜",
    "competition_status": "ç‹¬å®¶è¯¢ä»·|2-3å®¶æ¯”ä»·|å¤šå®¶æ¯”ä»·|ä»·æ ¼æ•æ„Ÿ",
    "customer_business_type": "æ‰¹å‘å•†|é›¶å”®å•†|å“ç‰Œå•†|è´¸æ˜“å…¬å¸|ç”µå•†|ç»ˆç«¯ç”¨æˆ·"
  },
  
  "æƒ…æ„Ÿä¸æ€åº¦": {
    "sentiment": "positive|neutral|negative|urgent|complaint",
    "tone": "ä¸“ä¸š|éšæ„|æ€¥èº|ç¤¼è²Œ|å¼ºç¡¬",
    "satisfaction_level": "æ»¡æ„|ä¸­ç«‹|ä¸æ»¡|æŠ•è¯‰"
  },
  
  "ç´§æ€¥åº¦è¯„ä¼°": {
    "urgency_level": "high|medium|low",
    "requires_urgent_response": true|false,
    "response_deadline": "1å°æ—¶å†…|4å°æ—¶å†…|24å°æ—¶å†…|3å¤©å†…",
    "business_impact": "critical|important|normal|low"
  },
  
  "å®¢æˆ·ç”»åƒæ¨æ–­": {
    "customer_type": "æ–°å®¢æˆ·|è€å®¢æˆ·|æ½œåœ¨å¤§å®¢æˆ·|ä½ä»·å€¼å®¢æˆ·|æœªçŸ¥",
    "customer_grade_suggestion": "Açº§ï¼ˆå¤§å®¢æˆ·ï¼‰|Bçº§ï¼ˆæˆé•¿å‹ï¼‰|Cçº§ï¼ˆæ½œåŠ›å®¢æˆ·ï¼‰|Dçº§ï¼ˆæ™®é€šè¯¢ç›˜ï¼‰",
    "professionalism": "ä¸“ä¸šä¹°å®¶|æ–°æ‰‹|ä¸­é—´å•†|ç›´æ¥å®¢æˆ·",
    "communication_style": "ç®€æ´é«˜æ•ˆ|è¯¦ç»†æ²Ÿé€š|æ­£å¼ä¸¥è°¨|å‹å¥½éšå’Œ"
  },
  
  "å†…å®¹åˆ†æ": {
    "summary": "é‚®ä»¶æ ¸å¿ƒå†…å®¹æ‘˜è¦ï¼ˆ50å­—å†…ï¼‰",
    "key_points": ["å…³é”®ä¿¡æ¯ç‚¹1", "å…³é”®ä¿¡æ¯ç‚¹2", "å…³é”®ä¿¡æ¯ç‚¹3"],
    "mentioned_products": ["æåŠçš„äº§å“"],
    "mentioned_quantities": "æ•°é‡ä¿¡æ¯",
    "mentioned_prices": "ä»·æ ¼ç›¸å…³",
    "mentioned_timeline": "æ—¶é—´è¦æ±‚",
    "questions_asked": ["å®¢æˆ·æå‡ºçš„é—®é¢˜"],
    "concerns": ["å®¢æˆ·çš„é¡¾è™‘"]
  },
  
  "è¡ŒåŠ¨å»ºè®®": {
    "next_action": "å…·ä½“çš„ä¸‹ä¸€æ­¥æ“ä½œå»ºè®®",
    "response_template_suggestion": "é¦–æ¬¡è¯¢ç›˜å›å¤|æŠ¥ä»·å•|æ ·å“ç¡®è®¤|è®¢å•ç¡®è®¤|å”®åå¤„ç†|è·Ÿè¿›é‚®ä»¶",
    "suggested_tags": ["ä¸šåŠ¡æ ‡ç­¾1", "ä¸šåŠ¡æ ‡ç­¾2"],
    "follow_up_date": "å»ºè®®è·Ÿè¿›æ—¶é—´ï¼ˆå¤©æ•°ï¼‰",
    "requires_human_review": true|false,
    "human_review_reason": "éœ€è¦äººå·¥å®¡æ ¸çš„åŸå› "
  },
  
  "é£é™©ä¸æœºä¼š": {
    "risk_level": "high|medium|low",
    "risk_factors": ["é£é™©å› ç´ "],
    "opportunity_score": 0-100,
    "conversion_probability": 0-100,
    "estimated_order_value": "é¢„ä¼°è®¢å•é‡‘é¢"
  }
}

ã€åˆ†æè¦ç‚¹ã€‘
1. æ ¹æ®é‚®ä»¶å†…å®¹åˆ¤æ–­å®¢æˆ·å¤„äºå“ªä¸ªä¸šåŠ¡é˜¶æ®µ
2. æ·±åº¦åˆ†æå®¢æˆ·çš„è´­ä¹°æ„å‘å¼ºåº¦ï¼ˆé€šè¿‡è¯­æ°”ã€ç»†èŠ‚é—®é¢˜ã€ç´§è¿«æ€§åˆ¤æ–­ï¼‰
3. è¯†åˆ«å®¢æˆ·çš„å†³ç­–æƒé™å’Œé‡‡è´­ä¸“ä¸šåº¦
4. è¯„ä¼°æ˜¯å¦å­˜åœ¨ç«äº‰å¯¹æ‰‹
5. æ¨æ–­å®¢æˆ·é¢„ç®—æ°´å¹³ï¼ˆé«˜ç«¯/ä¸­ç«¯/ä½ç«¯ï¼‰
6. æå–æ‰€æœ‰å…³é”®ä¸šåŠ¡ä¿¡æ¯ï¼ˆäº§å“ã€æ•°é‡ã€ä»·æ ¼ã€æ—¶é—´ï¼‰
7. ç»™å‡ºä¸ªæ€§åŒ–çš„å›å¤ç­–ç•¥å’Œè¡ŒåŠ¨å»ºè®®
8. æ ‡æ³¨æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥ï¼ˆå¤§é¢è®¢å•ã€æŠ•è¯‰ã€å¤æ‚éœ€æ±‚ï¼‰

è¯·ç¡®ä¿è¿”å›çš„æ˜¯çº¯JSONæ ¼å¼ï¼Œä¸è¦åŒ…å«markdownç¬¦å·ã€‚
"""
        return prompt
    
    async def _call_api(self, prompt: str, model: str) -> str:
        """è°ƒç”¨ aihubmix.com API"""
        
        url = f"{self.base_url}/chat/completions"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.3,
            "max_tokens": 2000
        }
        
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            response = await client.post(url, json=payload, headers=headers)
            response.raise_for_status()
            
            data = response.json()
            content = data['choices'][0]['message']['content']
            
            return content
    
    def _parse_analysis_result(self, result: str) -> Dict:
        """è§£æ AI è¿”å›çš„åˆ†æç»“æœï¼ˆå…¼å®¹å¤æ‚ç»“æ„ï¼‰"""
        
        try:
            # æ¸…ç†å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
            result = result.strip()
            if result.startswith("```json"):
                result = result[7:]
            if result.startswith("```"):
                result = result[3:]
            if result.endswith("```"):
                result = result[:-3]
            result = result.strip()
            
            # è§£æ JSON
            analysis = json.loads(result)
            
            # å°†æ–°ç»“æ„å¹³å¦åŒ–ä¸ºå…¼å®¹æ ¼å¼ï¼ˆä¿æŒä¸æ•°æ®åº“å­—æ®µä¸€è‡´ï¼‰
            flattened = {}
            
            # ä¸šåŠ¡é˜¶æ®µ
            if "ä¸šåŠ¡é˜¶æ®µåˆ†ç±»" in analysis:
                flattened["business_stage"] = analysis["ä¸šåŠ¡é˜¶æ®µåˆ†ç±»"].get("primary_stage", "")
                flattened["category"] = self._map_stage_to_category(flattened["business_stage"])
                flattened["secondary_category"] = analysis["ä¸šåŠ¡é˜¶æ®µåˆ†ç±»"].get("secondary_category", "")
            
            # å®¢æˆ·æ„å›¾
            if "å®¢æˆ·æ„å›¾è¯†åˆ«" in analysis:
                intent = analysis["å®¢æˆ·æ„å›¾è¯†åˆ«"]
                flattened["purchase_intent"] = intent.get("purchase_intent", "low")
                flattened["purchase_intent_score"] = intent.get("purchase_intent_score", 0)
                flattened["budget_level"] = intent.get("budget_level", "")
                flattened["urgency"] = intent.get("urgency", "")
                flattened["decision_authority"] = intent.get("decision_authority", "")
                flattened["competition_status"] = intent.get("competition_status", "")
                flattened["customer_business_type"] = intent.get("customer_business_type", "")
            
            # æƒ…æ„Ÿæ€åº¦
            if "æƒ…æ„Ÿä¸æ€åº¦" in analysis:
                emotion = analysis["æƒ…æ„Ÿä¸æ€åº¦"]
                flattened["sentiment"] = emotion.get("sentiment", "neutral")
                flattened["tone"] = emotion.get("tone", "")
                flattened["satisfaction_level"] = emotion.get("satisfaction_level", "")
            
            # ç´§æ€¥åº¦
            if "ç´§æ€¥åº¦è¯„ä¼°" in analysis:
                urgency = analysis["ç´§æ€¥åº¦è¯„ä¼°"]
                flattened["urgency_level"] = urgency.get("urgency_level", "medium")
                flattened["requires_urgent_response"] = urgency.get("requires_urgent_response", False)
                flattened["response_deadline"] = urgency.get("response_deadline", "")
                flattened["business_impact"] = urgency.get("business_impact", "")
            
            # å®¢æˆ·ç”»åƒ
            if "å®¢æˆ·ç”»åƒæ¨æ–­" in analysis:
                profile = analysis["å®¢æˆ·ç”»åƒæ¨æ–­"]
                flattened["customer_type"] = profile.get("customer_type", "æœªçŸ¥")
                flattened["customer_grade_suggestion"] = profile.get("customer_grade_suggestion", "")
                flattened["professionalism"] = profile.get("professionalism", "")
                flattened["communication_style"] = profile.get("communication_style", "")
            
            # å†…å®¹åˆ†æ
            if "å†…å®¹åˆ†æ" in analysis:
                content = analysis["å†…å®¹åˆ†æ"]
                flattened["summary"] = content.get("summary", "")
                flattened["key_points"] = content.get("key_points", [])
                flattened["mentioned_products"] = content.get("mentioned_products", [])
                flattened["mentioned_quantities"] = content.get("mentioned_quantities", "")
                flattened["mentioned_prices"] = content.get("mentioned_prices", "")
                flattened["mentioned_timeline"] = content.get("mentioned_timeline", "")
                flattened["questions_asked"] = content.get("questions_asked", [])
                flattened["concerns"] = content.get("concerns", [])
            
            # è¡ŒåŠ¨å»ºè®®
            if "è¡ŒåŠ¨å»ºè®®" in analysis:
                action = analysis["è¡ŒåŠ¨å»ºè®®"]
                flattened["next_action"] = action.get("next_action", "")
                flattened["response_template_suggestion"] = action.get("response_template_suggestion", "")
                flattened["suggested_tags"] = action.get("suggested_tags", [])
                flattened["follow_up_date"] = action.get("follow_up_date", "")
                flattened["requires_human_review"] = action.get("requires_human_review", False)
                flattened["human_review_reason"] = action.get("human_review_reason", "")
            
            # é£é™©æœºä¼š
            if "é£é™©ä¸æœºä¼š" in analysis:
                risk = analysis["é£é™©ä¸æœºä¼š"]
                flattened["risk_level"] = risk.get("risk_level", "low")
                flattened["risk_factors"] = risk.get("risk_factors", [])
                flattened["opportunity_score"] = risk.get("opportunity_score", 0)
                flattened["conversion_probability"] = risk.get("conversion_probability", 0)
                flattened["estimated_order_value"] = risk.get("estimated_order_value", "")
            
            # ä¿ç•™åŸå§‹å®Œæ•´æ•°æ®
            flattened["full_analysis"] = analysis
            
            # ç¡®ä¿åŸºæœ¬å­—æ®µå­˜åœ¨ï¼ˆä¸æ•°æ®åº“å­—æ®µå¯¹åº”ï¼‰
            required_fields = ['sentiment', 'category', 'urgency_level', 'purchase_intent', 'summary']
            for field in required_fields:
                if field not in flattened:
                    flattened[field] = 'unknown'
            
            return flattened
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON è§£æå¤±è´¥: {str(e)}")
            print(f"åŸå§‹ç»“æœ: {result}")
            return self._get_default_analysis()
    
    def _map_stage_to_category(self, stage: str) -> str:
        """å°†ä¸šåŠ¡é˜¶æ®µæ˜ å°„åˆ°ç®€å•åˆ†ç±»ï¼ˆå…¼å®¹æ•°æ®åº“ï¼‰"""
        mapping = {
            "æ–°å®¢è¯¢ç›˜": "inquiry",
            "æŠ¥ä»·è·Ÿè¿›": "quotation",
            "æ ·å“é˜¶æ®µ": "sample",
            "è°ˆåˆ¤è®®ä»·": "quotation",
            "è®¢å•ç¡®è®¤": "order",
            "ç”Ÿäº§è·Ÿè¸ª": "order",
            "å”®åæœåŠ¡": "complaint",
            "è€å®¢ç»´æŠ¤": "follow_up",
            "åƒåœ¾è¥é”€": "spam"
        }
        return mapping.get(stage, "spam")  # é»˜è®¤ä¸ºåƒåœ¾è¥é”€
    
    def _get_default_analysis(self) -> Dict:
        """è·å–é»˜è®¤åˆ†æç»“æœï¼ˆå½“ AI åˆ†æå¤±è´¥æ—¶ï¼‰"""
        return {
            "sentiment": "neutral",
            "category": "spam",  # æ”¹ä¸ºspamï¼ˆåƒåœ¾è¥é”€ï¼‰
            "urgency_level": "medium",
            "purchase_intent": "low",
            "summary": "AI åˆ†æå¤±è´¥ï¼Œéœ€è¦äººå·¥å¤„ç†",
            "key_points": [],
            "suggested_tags": [],
            "next_action": "äººå·¥å®¡æ ¸é‚®ä»¶",
            "customer_type": "æœªçŸ¥",
            "requires_urgent_response": False
        }
    
    async def generate_reply(
        self,
        subject: str,
        body: str,
        context: Dict = None,
        tone: str = "professional",
        model: str = "gpt-4o-mini",
        use_knowledge_base: bool = True,
        custom_prompt: Dict = None  # ğŸ”¥ æ–°å¢ï¼šè‡ªå®šä¹‰æç¤ºè¯
    ) -> Dict:
        """
        ç”Ÿæˆæ™ºèƒ½å›å¤
        
        å‚æ•°:
            subject: åŸé‚®ä»¶ä¸»é¢˜
            body: åŸé‚®ä»¶æ­£æ–‡
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå®¢æˆ·ä¿¡æ¯ã€å†å²é‚®ä»¶ç­‰ï¼‰
            tone: å›å¤è¯­æ°” (professional/friendly/formal)
            model: AI æ¨¡å‹
            use_knowledge_base: æ˜¯å¦ä½¿ç”¨å‘é‡çŸ¥è¯†åº“
            custom_prompt: è‡ªå®šä¹‰æç¤ºè¯ï¼ˆåŒ…å« system_prompt å’Œ user_prompt_templateï¼‰
            
        è¿”å›:
            å›å¤å†…å®¹å­—å…¸
        """
        try:
            # ğŸ”¥ æ–°å¢ï¼šå¦‚æœå¯ç”¨çŸ¥è¯†åº“ï¼Œå…ˆæ£€ç´¢ç›¸å…³çŸ¥è¯†
            knowledge_context = None
            if use_knowledge_base:
                knowledge_context = await self._search_knowledge(subject, body)
            
            # ğŸ”¥ ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯æˆ–é»˜è®¤æç¤ºè¯
            if custom_prompt:
                prompt = self._build_custom_prompt(
                    subject,
                    body,
                    context,
                    tone,
                    knowledge_context,
                    custom_prompt
                )
            else:
                prompt = self._build_reply_prompt(
                    subject, 
                    body, 
                    context, 
                    tone,
                    knowledge_context
                )
            
            result = await self._call_api(prompt, model)
            
            # ğŸ”¥ æ¸…ç†AIè¿”å›çš„å†…å®¹ï¼Œç§»é™¤HTMLæ–‡æ¡£æ ‡ç­¾
            cleaned_result = self._clean_html_response(result)
            
            return {
                "success": True,
                "reply": cleaned_result,
                "model": model,
                "knowledge_used": knowledge_context is not None and len(knowledge_context) > 0,
                "knowledge_context": knowledge_context or [],  # ğŸ”¥ è¿”å›çŸ¥è¯†åº“ä¸Šä¸‹æ–‡
                "generated_at": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå›å¤å¤±è´¥: {str(e)}")
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "reply": ""
            }
    
    async def _search_knowledge(self, subject: str, body: str) -> Optional[List[Dict]]:
        """
        ä»å‘é‡çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³çŸ¥è¯†
        
        å‚æ•°:
            subject: é‚®ä»¶ä¸»é¢˜
            body: é‚®ä»¶æ­£æ–‡
            
        è¿”å›:
            ç›¸å…³çŸ¥è¯†ç‰‡æ®µåˆ—è¡¨
        """
        try:
            from src.ai.vector_knowledge import VectorKnowledgeService
            from src.crm.database import get_session
            
            vector_service = VectorKnowledgeService()
            db = get_session()
            
            try:
                # ç»„åˆæŸ¥è¯¢æ–‡æœ¬
                query_text = f"{subject}\n{body}"
                
                # æœç´¢ç›¸å…³çŸ¥è¯†ï¼ˆå‰3æ¡ï¼‰
                results = await vector_service.search_similar(
                    query=query_text,
                    limit=3,
                    db_session=db
                )
                
                if results:
                    print(f"âœ… ä»çŸ¥è¯†åº“æ£€ç´¢åˆ° {len(results)} æ¡ç›¸å…³çŸ¥è¯†")
                    return results
                else:
                    print("âš ï¸ çŸ¥è¯†åº“æœªæ£€ç´¢åˆ°ç›¸å…³å†…å®¹")
                    return None
                    
            finally:
                db.close()
                
        except Exception as e:
            print(f"âš ï¸ çŸ¥è¯†åº“æ£€ç´¢å¤±è´¥: {str(e)}")
            return None
    
    def _clean_html_response(self, html_content: str) -> str:
        """
        æ¸…ç†AIè¿”å›çš„HTMLå†…å®¹ï¼Œç§»é™¤å¤šä½™çš„æ–‡æ¡£æ ‡ç­¾
        
        å‚æ•°:
            html_content: AIç”Ÿæˆçš„HTMLå†…å®¹
            
        è¿”å›:
            æ¸…ç†åçš„HTMLå†…å®¹
        """
        import re
        
        # ç§»é™¤HTMLæ–‡æ¡£å£°æ˜å’Œ<html>æ ‡ç­¾
        content = html_content.strip()
        
        # ç§»é™¤<!DOCTYPE>
        content = re.sub(r'<!DOCTYPE[^>]*>', '', content, flags=re.IGNORECASE)
        
        # ç§»é™¤<html>æ ‡ç­¾ï¼ˆåŒ…æ‹¬å±æ€§ï¼‰
        content = re.sub(r'<html[^>]*>', '', content, flags=re.IGNORECASE)
        content = re.sub(r'</html>', '', content, flags=re.IGNORECASE)
        
        # ç§»é™¤<head>éƒ¨åˆ†
        content = re.sub(r'<head>.*?</head>', '', content, flags=re.IGNORECASE | re.DOTALL)
        
        # ç§»é™¤<body>æ ‡ç­¾ä½†ä¿ç•™å†…å®¹
        content = re.sub(r'<body[^>]*>', '', content, flags=re.IGNORECASE)
        content = re.sub(r'</body>', '', content, flags=re.IGNORECASE)
        
        # ç§»é™¤å¼€å¤´çš„```htmlå’Œç»“å°¾çš„```ï¼ˆMarkdownä»£ç å—ï¼‰
        content = re.sub(r'^```html\s*', '', content, flags=re.IGNORECASE)
        content = re.sub(r'\s*```$', '', content)
        
        # æ¸…ç†å¤šä½™çš„ç©ºç™½
        content = content.strip()
        
        return content
    
    def _build_reply_prompt(
        self, 
        subject: str, 
        body: str, 
        context: Dict = None,
        tone: str = "professional",
        knowledge_context: Optional[List[Dict]] = None
    ) -> str:
        """æ„å»ºå›å¤ç”Ÿæˆæç¤ºè¯"""
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤–è´¸ä¸šåŠ¡å‘˜ã€‚è¯·æ ¹æ®æ”¶åˆ°çš„å®¢æˆ·é‚®ä»¶ï¼Œç”Ÿæˆä¸€å°ä¸“ä¸šçš„è‹±æ–‡å›å¤é‚®ä»¶ã€‚

åŸé‚®ä»¶ä¿¡æ¯ï¼š
ä¸»é¢˜: {subject}
æ­£æ–‡: {body}

"""
        if context:
            if context.get('customer_name'):
                prompt += f"å®¢æˆ·å§“å: {context['customer_name']}\n"
            if context.get('company_name'):
                prompt += f"å…¬å¸åç§°: {context['company_name']}\n"
            if context.get('history'):
                prompt += f"å¾€æ¥å†å²: {context['history']}\n"
        
        # ğŸ”¥ æ–°å¢ï¼šæ·»åŠ çŸ¥è¯†åº“ä¸Šä¸‹æ–‡
        if knowledge_context:
            prompt += "\nç›¸å…³çŸ¥è¯†åº“ä¿¡æ¯ï¼š\n"
            for idx, knowledge in enumerate(knowledge_context, 1):
                prompt += f"{idx}. {knowledge['content'][:300]}...\n"
            prompt += "\nè¯·å‚è€ƒä»¥ä¸ŠçŸ¥è¯†åº“ä¿¡æ¯æ¥ç”Ÿæˆå›å¤ã€‚\n"
        
        tone_desc = {
            "professional": "ä¸“ä¸šã€ç¤¼è²Œ",
            "friendly": "å‹å¥½ã€äº²åˆ‡", 
            "formal": "æ­£å¼ã€ä¸¥è°¨",
            "enthusiastic": "çƒ­æƒ…ã€ç§¯æ"  # ğŸ”¥ æ–°å¢
        }
        
        prompt += f"""
å›å¤è¦æ±‚ï¼š
1. è¯­æ°”ï¼š{tone_desc.get(tone, 'ä¸“ä¸š')}
2. è¯­è¨€ï¼šä½¿ç”¨æµåˆ©çš„è‹±æ–‡
3. æ ¼å¼ï¼š**ä½¿ç”¨HTMLæ ¼å¼**ï¼Œä½¿ç”¨<p>æ ‡ç­¾åˆ†æ®µï¼Œä½¿ç”¨<br>æ¢è¡Œ
4. å†…å®¹ï¼šé’ˆå¯¹å®¢æˆ·çš„é—®é¢˜ç»™å‡ºä¸“ä¸šå›å¤
5. ç»“æ„ï¼š
   - å¼€å¤´ï¼šä¸“ä¸šçš„é—®å€™è¯­ï¼ˆDear XXX,ï¼‰
   - æ­£æ–‡ï¼šä½¿ç”¨<p>æ ‡ç­¾å°†ä¸åŒä¸»é¢˜åˆ†æˆå¤šä¸ªæ®µè½
   - åˆ—è¡¨ï¼šå¦‚æœæœ‰å¤šä¸ªè¦ç‚¹ï¼Œä½¿ç”¨<ul><li>æˆ–ç¼–å·åˆ—è¡¨
   - ç»“å°¾ï¼šä¸“ä¸šçš„ç»“æŸè¯­ï¼ˆBest regards, Sincerelyç­‰ï¼‰å’Œå®Œæ•´ç­¾åå—
6. ç­¾åæ ¼å¼ï¼š
   ```
   <p>Best regards,</p>
   <p>
   [Your Name]<br>
   [Your Position]<br>
   [Your Company]<br>
   Email: sales@underwearexport.com<br>
   WhatsApp: +86 138 xxxx xxxx
   </p>
   ```

**é‡è¦**: 
- æ¯ä¸ªæ®µè½å¿…é¡»ç”¨<p>æ ‡ç­¾åŒ…è£¹
- æ®µè½ä¹‹é—´ä¼šè‡ªåŠ¨æœ‰é—´è·
- ä¸è¦å°†æ‰€æœ‰å†…å®¹æŒ¤åœ¨ä¸€ä¸ªæ®µè½ä¸­
- **ä¸è¦ç”Ÿæˆå®Œæ•´çš„HTMLæ–‡æ¡£ç»“æ„ï¼ˆä¸è¦åŒ…å«<!DOCTYPE>, <html>, <head>, <body>ç­‰æ ‡ç­¾ï¼‰**
- **ç›´æ¥ç”Ÿæˆé‚®ä»¶æ­£æ–‡çš„HTMLç‰‡æ®µï¼Œä»Dearå¼€å¤´å³å¯**
- ä¸è¦åŒ…å«"Subject:"ç­‰æ ‡è®°

è¯·ç›´æ¥ç”ŸæˆHTMLæ ¼å¼çš„é‚®ä»¶æ­£æ–‡ç‰‡æ®µï¼ˆä¸è¦åŒ…å«æ–‡æ¡£å£°æ˜å’Œæ ‡ç­¾ï¼‰ã€‚
"""
        return prompt
    
    def _build_custom_prompt(
        self,
        subject: str,
        body: str,
        context: Dict = None,
        tone: str = "professional",
        knowledge_context: Optional[List[Dict]] = None,
        custom_prompt: Dict = None
    ) -> str:
        """ğŸ”¥ ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿æ„å»ºæç¤ºè¯"""
        
        # æ„å»ºå˜é‡å­—å…¸
        tone_desc = {
            "professional": "ä¸“ä¸šã€ç¤¼è²Œ",
            "friendly": "å‹å¥½ã€äº²åˆ‡",
            "formal": "æ­£å¼ã€ä¸¥è°¨",
            "enthusiastic": "çƒ­æƒ…ã€ç§¯æ"
        }
        
        # æ„å»ºçŸ¥è¯†åº“ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        knowledge_str = ""
        if knowledge_context:
            knowledge_str = "\nç›¸å…³çŸ¥è¯†åº“ä¿¡æ¯ï¼š\n"
            for idx, knowledge in enumerate(knowledge_context, 1):
                knowledge_str += f"{idx}. {knowledge['content'][:300]}...\n"
            knowledge_str += "\nè¯·å‚è€ƒä»¥ä¸ŠçŸ¥è¯†åº“ä¿¡æ¯æ¥ç”Ÿæˆå›å¤ã€‚\n"
        
        # æ„å»ºå®¢æˆ·ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        customer_str = ""
        if context:
            if context.get('customer_name'):
                customer_str += f"å®¢æˆ·å§“å: {context['customer_name']}\n"
            if context.get('company_name'):
                customer_str += f"å…¬å¸åç§°: {context['company_name']}\n"
            if context.get('history'):
                customer_str += f"å¾€æ¥å†å²: {context['history']}\n"
        
        # æ¸²æŸ“æ¨¡æ¿
        variables = {
            "subject": subject,
            "body": body,
            "tone_desc": tone_desc.get(tone, "ä¸“ä¸š"),
            "knowledge_context": knowledge_str,
            "customer_context": customer_str
        }
        
        try:
            # æ¸²æŸ“ç”¨æˆ·æç¤ºè¯æ¨¡æ¿
            user_prompt = custom_prompt['user_prompt_template'].format(**variables)
            
            # å¦‚æœæœ‰ç³»ç»Ÿæç¤ºè¯ï¼Œæ‹¼æ¥èµ·æ¥
            if custom_prompt.get('system_prompt'):
                final_prompt = f"{custom_prompt['system_prompt']}\n\n{user_prompt}"
            else:
                final_prompt = user_prompt
            
            return final_prompt
            
        except KeyError as e:
            # å¦‚æœæ¨¡æ¿å˜é‡é”™è¯¯ï¼Œå›é€€åˆ°é»˜è®¤æç¤ºè¯
            print(f"âš ï¸ æ¨¡æ¿å˜é‡é”™è¯¯: {e}ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
            return self._build_reply_prompt(subject, body, context, tone, knowledge_context)


# å…¨å±€å®ä¾‹
_analyzer_instance = None

def get_analyzer() -> EmailAIAnalyzer:
    """è·å– AI åˆ†æå™¨å•ä¾‹"""
    global _analyzer_instance
    if _analyzer_instance is None:
        _analyzer_instance = EmailAIAnalyzer()
    return _analyzer_instance
